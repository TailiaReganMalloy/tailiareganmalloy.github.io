---
title: "Attending Queer in AI Workshop at EurIPS"
date: 2025-12-06
draft: false 
toc: false
layout: post
permalink: /posts/2025-09-12
author_profile: false
tags:
  - Large Language Models
  - Experiment 
---

## Affinity Workshop  [Queer in AI](https://www.queerinai.com/eurips-2025)

## Keynote by Beckett LeClair: **AI, Queer Youth, and a Call to Action:** 
We are seeing a surge of anti-queer rhetoric masked as children’s protection, and to an extent vice versa. This false dichotomy serves no one but those who would disregard both groups, and in doing so overlooks those facing intersecting barriers from both their youth and their queerness. There are countless opportunities and risks that AI/ML pose to our youth, with some of those being disproportionately felt by queer kids in particular. The good news is that the research community is well-equipped to meet the rising need for evidence, data and solutions – we just need to know where to look. In this talk, I will discuss some of the sociotechnical impacts on queer youth through a fundamental child rights lens, spotlighting the areas where increased research and collaboration will be vital going forward.

- [5RightsFoundation](https://5rightsfoundation.com/) 

### Think of the children
Relationship between advocacy of the rights of children and advocacy of the rights of queer or otherwise margninalized peoples. AI/ML researchers and engineers aren't taught how to identify the rights of groups that thety are not a part of. UNCRC defines the rights of children but no similar document for queer people, there are also more specific descriptions of rights like GC25 which defines digital rights. But these documents are clear in that these rights are as applicable to queer children as they are to other groups of children. 

Article 3 (best interests of the child) The best interests of the child must be a top priority in all decisions and actions that affect children.
- An adults judgement of a childs best interest cannot override the oblidation to respect all children's rights in the convention. 
- What is the definition of a controvention on the definition of the rights of children? 

article 12 (respect for the views  of the child) Every child has the right to express their views, feelings and wishes in all matters affecting them, and to have their views considered and taken seriously. This right applies at all times, for example during immigration proceedings, housing decisions or the child’s day-to-day home life. 
- Relates to article 3 with respect to queer youth... 
- Abuse of the concept of child's est interest can be used to justify racist policies and anti-queer policies. General comment 14 (?) 
- Ci;tira; odemtoty cammpt excise pr kistofy tje [er[etiatopm pf tradotopms tjat demy cjo;drem rogjts guaranteed by the convention.  (totally fucked up this part whoops). 

What are examples of discrimination against children and queer children by AI systems, algorithmically downranking or censorship. Educational technology failing to reflect the realities of queer history and experience. These result in queer children changing their behavior and using systems that are less well structured and more vulnerable to be the target of predation. 
- Children have expressed ideas like algorithms discovering that they were queer before they did, raising the question of the impact of changing algorithms in an attempt to protect children when in actuality it is done to strengthen traditional cultural values. 

Potential beneficial applications of AI in queer and children's rights. Improving allocation of resources to queer children like gender affirming care. Improvements to online spaces that can better foster community. queer children are concerned with the impact of AI on children and teens mental safety and especially that of minorities. They do have hopes for the future of AI like training models that are free from gender and secuality biases. 

[IEEE Standard for an Age Appropriate Digital Services Framework Based on the 5Rights Principles for Children](https://standards.ieee.org/ieee/2089/7633/ )
This standard for an age appropriate digital services framework is based on the 5Rights Foundation principles in order to help build the digital world young people deserve. Organizations are becoming increasingly aware of the need to treat children as a separate user group to support their engagement in the digital world. Children and their parents and responsible adults have established rights, and specific vulnerabilities associated with their age which require special consideration. Organizations make decisions and take actions that affect not just their financial bottom line, but also the rights and needs of children and young people. This Standard offers organizations the opportunity to create services that uphold children and young people’s rights and support their evolving capacity. For the purposes of this standard, a child is any person under the age of 18.

### Think with the children 

## In-Person Presentations

### WinoQueer-NL: Assessing Bias in Dutch Language Models toward LGBTQ+ Identities

**Jiska Beuk & Gerasimos Spanakis** | Maastricht University

While English language models have been widely examined for anti-queer bias, Dutch models remain understudied. We developed a culturally and linguistically adapted Dutch dataset based on the English WinoQueer benchmark, validated through an online survey with 43 Dutch queer participants. The final dataset comprises 42,906 sentences evaluated using Dutch-specific and multilingual models. Our findings reveal significant disparities, with transgender and non-binary identities consistently receiving the highest bias scores despite overall neutral means.

https://aclanthology.org/2023.acl-long.507v3.pdf
What general anti-LGBTQ+ stereotypes or biases have harmed you? What stereotypes or biases about your gender identity have harmed you? What stereotypes or biases about your sexual/romantic orientation have harmed you? What stereotypes or biases about the intersection of your gender & sexual identities have harmed you?

![](https://i.imgur.com/CXzhrBY.png)

43 queer dutch speakers were surveyed about their percpetion of the harmfullness of various sentences in dutch about queer people. This resulting dataset can be used to compare the bias that exists in LLMs by comparing masked sentence token probabilities of counterfactual terms (stright/queer). 

- What are the differences of LLM bias between in-group and out-group biased language of queer stereotypes. 

![](https://i.imgur.com/jnIidVK.png)

50% is the target for 'fair', but below represents 'over correction', what are some examples of how models can be over correcting for biased language? For dutch, many of the more biased groups (trans, non-binary) are the same across english and dutch language models. 

Questions: 
- Who were the 43 people that were surveyed, and were many of them bilingual? 
- Have you looked into the soruces for some of the biases? A: this is difficult to know because it is a combination of the effects of the dataset that models are trained on and the debiasing techniques that were used. 
- LLama 3.2-1B had a score of 5 for 'gay', how does this type of overcorrecting impact the way that models percieve of concepts. 

### Glitter: A Multi-Sentence, Multi-Reference Benchmark for Gender-Fair German Machine Translation

**A Pranav** | University of Hamburg

GLITTER is a comprehensive benchmark for evaluating gender-fair German machine translation that addresses limitations in how current MT systems handle inclusive gender representation beyond binary forms. The work involves creating professionally-annotated multi-sentence passages with three gender-fair alternatives (neutral rephrasing, typographical solutions like gender-star, and neologistic forms) to advance research in non-exclusionary translation technologies.

## Policy impact from AI regulation to policy inclusion. 

Google scholar, mendeley, and other research reposotiries can be difficult to update for trans people, married or divorced women, people who want to adjust their identity for reasons of cultural identity. 
- This is exacerbated by the lack of name change policy for proactive name changes that can be made quickly and effectively. 

Correct citations of names do increase overtime, mainly because people often get citations from the links in scholar and if they are updated there then it will be cited correctly. Scholar however does still have information on old names, which can be difficult for trans people. 

Questions / comments 
- One really good thing is Arxiv where you can change your name and it will change the name within the PDF of the files that are on the site. 
- One big issue for me outside of google scholar is that several sites like NIH and Harvard will download all publically available open source papers added to for instance arxiv, and host the original versions without a clear way to update it. Updating the papers on arxiv does not update these databases. 
- Concern about outing is important and some of the suggestions made seem like it will be highlighting that an author has changed their name, so how do you balance these two issues. 


## Virtual Presentations

### Bodies under Algorithmic Siege: Codes of Deception and Detection

**Christoffer Koch Andersen** | University of Cambridge

This talk argues that the contemporary algorithmic rendering of trans bodies as deceptive is part of a longer legacy of constructing gender nonconformity as innately deceptive. By thinking of transness as a constructed deception and algorithms as tools of detection, we examine how colonial discourses have become encoded into binary code, forming a "coded deception" that operates at the level of the trans body through algorithmic logic.

Body scanning technology requires the security people to try to guess what the gender of the person is, and there are only two options. Trans men who have binders have this issue, or preop/noop transwomen. Similar issues are facial recognition systems that can out trans people or identify them to governments that are anti-trans rights. Catrgorizing differences as an act of violence now and in the past in a colonialist sense of differentiating humans from those who are inhummanized. Important to understand algorithmic bias in this context to understand it as an act of violence. The history of deception and detection (i.e who is seen as needing to decieve and how others attempt to ditect them). [Evil decievers and make believs on transphobic violence and the politics of illusion](https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1527-2001.2007.tb01090.x?casa_token=nctPQuAadoAAAAAA%3AtSN9oTsp-HvOMmr6tWEHxzww_3hlzLwzdmGcL-b7DwB-rxvZ6dVKkL1MXC654Gb8kp6lFefKX_7WvN-I). 
