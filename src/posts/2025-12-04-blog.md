---
title: "EurIPS 2025 Conference"
date: 2025-12-04
draft: false 
toc: false
layout: post
permalink: /posts/2025-12-04
author_profile: false
tags:
  - Conference
  - Artificial Intelligence 
---

# EuroIPS 2025 Copenhagen

## [Keynote  **Sepp Hochreiter**  (chair Stella Graẞhof)](https://eurips.cc/conference/talks/#keynote:sepp-hochreiter): Sustainable, low-energy and fast AI made in Europe

### Scaling up Artifical Intelligence
![Encyclopedia 04 00028 g001](https://www.mdpi.com/encyclopedia/encyclopedia-04-00028/article_deploy/html/images/encyclopedia-04-00028-g001.png)

Four manufacturing paradigms have been driven by changes in technology and customer needs (schematic diagram by Koren, adapted with permission from Ref. [[7](https://www.mdpi.com/2673-8392/4/1/28#B7-encyclopedia-04-00028)], Copyright 2010 John Wiley & Sons, Inc., Hoboken, NJ, USA). [Image source](https://www.mdpi.com/2673-8392/4/1/28)

Olympus model has 2 Trillion parameters which was made in early 2024 at a time when the belief was that more data and more parameters will indefinitely lead to improved performance. Diminishing returns for improvements in performance past the point of optimal efficiency zones towards the zone of diminishing returns. 

[Frontier clodes models show performance about 9 months in advance of open models run on consumer GPUs.](https://epoch.ai/data-insights/consumer-gpu-model-gap)

![figure 1](https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41467-025-61040-5/MediaObjects/41467_2025_61040_Fig1_HTML.png)

Other results show that small edge devices with low hardware are also showing a trend of lagging behind modes run on larger devices. This incresaes the applicability of models into daily tasks that would be impossible when running on a large cluster. Smaller models are getting better at difficult tasks like agentic settings and reasoning capabilities. 

What is the motication for smaller models other than better runtime and efficiency? We used up all of the data in the internet to train the massive models so we need to look elsewhere to increase the performance of LLMs. Knoweldge extraction is one approach, instead of putting more information into the models you get better at taking information out of the models. Still room for improvement... 

![2024_12_16_SLMs_2](https://cdn-bdmhh.nitrocdn.com/JNiKLBzGPsfbQJqUQoZqIbUrxBklWopT/assets/images/optimized/rev-7c98781/objectbox.io/wordpress/wp-content/uploads/2024/12/2024_12_16_SLMs_2-1-1.png)

Benefits of small language models, cost efficiency, less energy, embedded deployment on edge and mobile.  Privacy concerns are better due to on premise or local deployment. Sometimes there is less accuracy, often looking for the target of being good enough for many tasks. Easy and affordable fine tuning allowing for better customization, lightweight assistant applications. 

### Industrialization of AI using SLMs, xLSTM [NXAI](https://www.nx-ai.com/) 

[Extended Long-Short Term Memory](https://proceedings.neurips.cc/paper_files/paper/2024/hash/c2ce2f2701c10a2b2f2ea0bfa43cfaa3-Abstract-Conference.html)

sLSTM: 
![](https://i.imgur.com/t3fNSwq.png)

mLSTM: 
![](https://i.imgur.com/lsFsrxe.png)

xLSTMs have better performance than tansformers for a given computer and also has faster performance during training. Linear run time at inference compared to quadratic run time of transformer models. These aspects mean that xLSTMs have important industrial applications like robotics, self driving, etc. 

xLSTMs have stable performance for larger contexts like 16000 token settings where xLSTMs can still process tokens faster than Transformers. 

### TiRex: Time series foundation models from xLSTMs 

![](https://i.imgur.com/RO1iaVn.png)

Architecture overview of TiRex. The model comprises two main components: the xLSTM blocks and a residual block in the input and output layers. The illustrated forecast shows the forecasted series is in blue and the forecast of TiRex in orange. During inference, only the last three output windows are of interest. [Paper](https://arxiv.org/pdf/2505.23719) 

![](https://i.imgur.com/uK9R3Az.png)

Chomsky model of the abilities of different AI model structures, LSTMs can count so they have this difference in performance.

Asked a question from the audience about the worse perofrmance of xLSTMs in needle in the haystack tasks with long context windows in which transformers outperform, but he says 

### My questions: 
1. Why are you going back to lstms, is it not possible to do energy efficency using transformers? In the paper the main comparison was against things like Mamba and LLama but other approaches are designed for faster inference running or training improvements while also relying on transformers. 
2.  What about energy based transformers. 
3. Is distillation a valid approach for Europe given the issues of using certain models due to GDPR and the EU AI Act. 
4. Why would you use a transformer to control a drone 

## [Paper Talks  (chair Stella Graẞhof)](https://eurips.cc/conference/talks/#thu-session-2)

### In Search of Adam’s Secret Sauce: Antonio Orvieto, Robert Gower

Understanding the remarkable efficacy of Adam when training transformer-based language models has become a central research topic within the optimization community. To gain deeper insights, several simplifications of Adam have been proposed, such as the signed gradient and signed momentum methods. In this work, we conduct an extensive empirical study — training over 1,300 language models across different data configurations and scales — comparing Adam to several known simplified variants. We find that signed momentum methods consistently underperform relative to Adam, even after careful tuning of momentum parameters, clipping setting and learning rates. However, our analysis reveals a compelling option that preserves optimal performance while allowing for new insightful reformulations: constraining the Adam momentum parameters to be equal, $\beta_1=\beta_2$. Beyond robust performance, this choice affords new theoretical insights, directly highlights the ``secret sauce’’ on top of signed momentum, and grants a precise statistical interpretation: we show that Adam in this setting implements a natural online algorithm for estimating the mean and variance of gradients—one that arises from a mean-field Gaussian variational inference perspective.

### Understanding Prompt Tuning and In-Context Learning via Meta-Learning: Tim Genewein, Kevin Li, Jordi Grau-Moya, Anian Ruoss, Laurent Orseau, Marcus Hutter

Prompting is one of the main ways to adapt a pretrained model to target tasks. Besides manually constructing prompts, many prompt optimization methods have been proposed in the literature. Method development is mainly empirically driven, with less emphasis on a conceptual understanding of prompting. In this paper we discuss how optimal prompting can be understood through a Bayesian view, which also implies some fundamental limitations of prompting that can only be overcome by tuning weights. The paper explains in detail how meta-trained neural networks behave as Bayesian predictors over the pretraining distribution, whose hallmark feature is rapid in-context adaptation. Optimal prompting can be studied formally as conditioning these Bayesian predictors, yielding criteria for target tasks where optimal prompting is and is not possible. We support the theory with educational experiments on LSTMs and Transformers, where we compare different versions of prefix-tuning and different weight-tuning methods. We also confirm that soft prefixes, which are sequences of real-valued vectors outside the token alphabet, can lead to very effective prompts for trained and even untrained networks by manipulating activations in ways that are not achievable by hard tokens. This adds an important mechanistic aspect beyond the conceptual Bayesian theory.

## Keynote  **Yejin Choi**  streamed from NeurIPS San Diego: The art of AI reasoning. 

Democratizing GAI by transcending scaling laws. This was motivated by past observations that scaling up works well and remains a major component of the sucess of GAI today. However there are alternatives to this, three major ones are unconventional data, algorithms, or collaboration. 

Some people argue: The era of brute force scaling is over and the future will require more intelligent scaling like focusing on pretraining with better hardware, algorithms, etc, because we aren't getting more data. 

There is a debate over how much things are plateauing. Some important future focuses are learning better and faster with limited data, synthesizing new data (because data is all you need and is the only proven way of making things work) and trying to reason beyond what is in the data, because humans have a natural ability to reason beyond data. 

- I think that human ability of generalizing isn't necressarily better than AI, but that humans have been taught how to generalize in a way that other humans can expect and interact with easily. When AI tires to generalize from only working on data without interacting with humans (no RLHF doesn't count) then it means they behave unexpectedly. 

The rise of large reasoning models, as opposed to llms has shown that SFT memorizes wheras RL generalizes. 

![](https://i.imgur.com/iQ8bA9e.jpeg)

LLMs tend to behave homogenously both inter and intra model when performing open ended tasks, and this effect is exacerbated in post-trained models

https://arxiv.org/pdf/2504.13837

The chemistry between results of effortful RL are not the same as results with effortless RL. There is an important aspect of effortful RL. DARPO and GRPO algoritthms. Prolonged RL. When there are clips used for RL function rewards it happens that the clips that you use matter a lot, and train test performance can be surprisingly different if you clip too high or too low. 

ProRL shows comparable performance to models that are 4.5x as large, which is a really difficult gap in performance to overcome. BroRL (broadened RL) happens to do better than prolonged RL. Proloooooooonged RL on 1.5B models can go faaaaaaaar. But we need to figure out what is going on about this.

Many recent papers have focused on entropy in Reinforcement Learning. Entropy refularized policy optimization (or evolutionary policy optimization) have looked at these things. 

Conclusions from effortless SFT are not the same as the conclusions from effortful SFT, in a similar way as the previous effect. 

Synthetic data is one of the sollutions to data being the 'fossile fule' of AI training. If people have a lot of resources then their decision making around data sourcing is very different from people who have less resources. Curse of recursion paper shows that training on LLM generated data leads to forgetting. 

The idea of data diversity being important has to do with out of distribution generalization, which is what everyone cares about. Synthetic data generation often involves massive 100s of billions of model size, and some approaches can be used to improve the quality of data generated by much smaller moels (32B) like using a gradient based diversity filter which can be used to find which are the under and overrepresented data clusteres, to fins the best mullion or so datapoints that can be used to train a much smaller model. 

Prysmatic synthesis PrismMath-7B was at the time outperforming model baselines that were using the big teacher models and relied on human labeled problems and answers. This shows some of the limits that can be pushed by using more synthetic data (i.e data that is more synthetic). RL is a fancy data synthesis method which looks fancier than SNT but it is allowing the model to generate its own data and only being satisfctory when the data starts to look like the real data. 

Reinforcement learnig as a pre-training objective. Next token prediction using reasoning with NLP tries to allow the model to think for itself for a bit before predicting oken. So there is an information gain for predicting the next token using the thoughts that the LLM generates, and this leads to a reward over the improvement between thinking vs. not thinking. 

Reward in terms of information gain in predicting the next token with vs. without thought (your own thought) gives you reward. Importnt questions are whether we can do RLP with a base model without any prior task specific tuning, and does the gain of RLP survive even after SFT+RLVR. Also, can RLP when applied to an earlier pretraining checkpoint wth 200B less tokens to match the pretraining flops, match the performance of a fully trained base model. This question helps answer wether or not the training was beneficial form a perspective of what you should do with a cetrain amount of FLOPs and a model that you want to train. 

![](https://i.imgur.com/yMHulPa.png)

 Super effortful SFT can win over effortful RL, showing the importance of RL in pretraining for reasoning models. https://www.openthoughts.ai/blog/ot3 This unique method of collaborating has some impressive results and is different from typical approaches to slicing research into smaller and smaller pieces to publish a lot and get a lot of citations, etc. 

On the art of artificial reasoning: Lots of disagreement between what the future of state of the art models are. How do we generate enough synthetic data to cover the universe of knowledge... Questions like 'how do we cure cancer', there is some universe of this knowledge that exists in theory but may require extreme scale reasoning. Groups of knowledge areas include knowledge in the unconventional simulation and knowledge in the extreme scale reasoning. 

# Day three 

## [Paper Talks  (chair Joakim Bruslund Haurum)](https://eurips.cc/conference/talks/#fri-session-1)

## Affinity Workshop  [Queer in AI](https://www.queerinai.com/eurips-2025)

## Keynote by Beckett LeClair: **AI, Queer Youth, and a Call to Action:** 
We are seeing a surge of anti-queer rhetoric masked as children’s protection, and to an extent vice versa. This false dichotomy serves no one but those who would disregard both groups, and in doing so overlooks those facing intersecting barriers from both their youth and their queerness. There are countless opportunities and risks that AI/ML pose to our youth, with some of those being disproportionately felt by queer kids in particular. The good news is that the research community is well-equipped to meet the rising need for evidence, data and solutions – we just need to know where to look. In this talk, I will discuss some of the sociotechnical impacts on queer youth through a fundamental child rights lens, spotlighting the areas where increased research and collaboration will be vital going forward.

- [5RightsFoundation](https://5rightsfoundation.com/) 

### Think of the children
Relationship between advocacy of the rights of children and advocacy of the rights of queer or otherwise margninalized peoples. AI/ML researchers and engineers aren't taught how to identify the rights of groups that thety are not a part of. UNCRC defines the rights of children but no similar document for queer people, there are also more specific descriptions of rights like GC25 which defines digital rights. But these documents are clear in that these rights are as applicable to queer children as they are to other groups of children. 

Article 3 (best interests of the child) The best interests of the child must be a top priority in all decisions and actions that affect children.
- An adults judgement of a childs best interest cannot override the oblidation to respect all children's rights in the convention. 
- What is the definition of a controvention on the definition of the rights of children? 

article 12 (respect for the views  of the child) Every child has the right to express their views, feelings and wishes in all matters affecting them, and to have their views considered and taken seriously. This right applies at all times, for example during immigration proceedings, housing decisions or the child’s day-to-day home life. 
- Relates to article 3 with respect to queer youth... 
- Abuse of the concept of child's est interest can be used to justify racist policies and anti-queer policies. General comment 14 (?) 
- Ci;tira; odemtoty cammpt excise pr kistofy tje [er[etiatopm pf tradotopms tjat demy cjo;drem rogjts guaranteed by the convention.  (totally fucked up this part whoops). 

What are examples of discrimination against children and queer children by AI systems, algorithmically downranking or censorship. Educational technology failing to reflect the realities of queer history and experience. These result in queer children changing their behavior and using systems that are less well structured and more vulnerable to be the target of predation. 
- Children have expressed ideas like algorithms discovering that they were queer before they did, raising the question of the impact of changing algorithms in an attempt to protect children when in actuality it is done to strengthen traditional cultural values. 

Potential beneficial applications of AI in queer and children's rights. Improving allocation of resources to queer children like gender affirming care. Improvements to online spaces that can better foster community. queer children are concerned with the impact of AI on children and teens mental safety and especially that of minorities. They do have hopes for the future of AI like training models that are free from gender and secuality biases. 

[IEEE Standard for an Age Appropriate Digital Services Framework Based on the 5Rights Principles for Children](https://standards.ieee.org/ieee/2089/7633/ )
This standard for an age appropriate digital services framework is based on the 5Rights Foundation principles in order to help build the digital world young people deserve. Organizations are becoming increasingly aware of the need to treat children as a separate user group to support their engagement in the digital world. Children and their parents and responsible adults have established rights, and specific vulnerabilities associated with their age which require special consideration. Organizations make decisions and take actions that affect not just their financial bottom line, but also the rights and needs of children and young people. This Standard offers organizations the opportunity to create services that uphold children and young people’s rights and support their evolving capacity. For the purposes of this standard, a child is any person under the age of 18.

### Think with the children 

## In-Person Presentations

### WinoQueer-NL: Assessing Bias in Dutch Language Models toward LGBTQ+ Identities

**Jiska Beuk & Gerasimos Spanakis** | Maastricht University

While English language models have been widely examined for anti-queer bias, Dutch models remain understudied. We developed a culturally and linguistically adapted Dutch dataset based on the English WinoQueer benchmark, validated through an online survey with 43 Dutch queer participants. The final dataset comprises 42,906 sentences evaluated using Dutch-specific and multilingual models. Our findings reveal significant disparities, with transgender and non-binary identities consistently receiving the highest bias scores despite overall neutral means.

https://aclanthology.org/2023.acl-long.507v3.pdf
What general anti-LGBTQ+ stereotypes or biases have harmed you? What stereotypes or biases about your gender identity have harmed you? What stereotypes or biases about your sexual/romantic orientation have harmed you? What stereotypes or biases about the intersection of your gender & sexual identities have harmed you?

![](https://i.imgur.com/CXzhrBY.png)

43 queer dutch speakers were surveyed about their percpetion of the harmfullness of various sentences in dutch about queer people. This resulting dataset can be used to compare the bias that exists in LLMs by comparing masked sentence token probabilities of counterfactual terms (stright/queer). 

- What are the differences of LLM bias between in-group and out-group biased language of queer stereotypes. 

![](https://i.imgur.com/jnIidVK.png)

50% is the target for 'fair', but below represents 'over correction', what are some examples of how models can be over correcting for biased language? For dutch, many of the more biased groups (trans, non-binary) are the same across english and dutch language models. 

Questions: 
- Who were the 43 people that were surveyed, and were many of them bilingual? 
- Have you looked into the soruces for some of the biases? A: this is difficult to know because it is a combination of the effects of the dataset that models are trained on and the debiasing techniques that were used. 
- LLama 3.2-1B had a score of 5 for 'gay', how does this type of overcorrecting impact the way that models percieve of concepts. 

### Glitter: A Multi-Sentence, Multi-Reference Benchmark for Gender-Fair German Machine Translation

**A Pranav** | University of Hamburg

GLITTER is a comprehensive benchmark for evaluating gender-fair German machine translation that addresses limitations in how current MT systems handle inclusive gender representation beyond binary forms. The work involves creating professionally-annotated multi-sentence passages with three gender-fair alternatives (neutral rephrasing, typographical solutions like gender-star, and neologistic forms) to advance research in non-exclusionary translation technologies.

## Policy impact from AI regulation to policy inclusion. 

Google scholar, mendeley, and other research reposotiries can be difficult to update for trans people, married or divorced women, people who want to adjust their identity for reasons of cultural identity. 
- This is exacerbated by the lack of name change policy for proactive name changes that can be made quickly and effectively. 

Correct citations of names do increase overtime, mainly because people often get citations from the links in scholar and if they are updated there then it will be cited correctly. Scholar however does still have information on old names, which can be difficult for trans people. 

Questions / comments 
- One really good thing is Arxiv where you can change your name and it will change the name within the PDF of the files that are on the site. 
- One big issue for me outside of google scholar is that several sites like NIH and Harvard will download all publically available open source papers added to for instance arxiv, and host the original versions without a clear way to update it. Updating the papers on arxiv does not update these databases. 
- Concern about outing is important and some of the suggestions made seem like it will be highlighting that an author has changed their name, so how do you balance these two issues. 


## Virtual Presentations

### Bodies under Algorithmic Siege: Codes of Deception and Detection

**Christoffer Koch Andersen** | University of Cambridge

This talk argues that the contemporary algorithmic rendering of trans bodies as deceptive is part of a longer legacy of constructing gender nonconformity as innately deceptive. By thinking of transness as a constructed deception and algorithms as tools of detection, we examine how colonial discourses have become encoded into binary code, forming a "coded deception" that operates at the level of the trans body through algorithmic logic.

Body scanning technology requires the security people to try to guess what the gender of the person is, and there are only two options. Trans men who have binders have this issue, or preop/noop transwomen. Similar issues are facial recognition systems that can out trans people or identify them to governments that are anti-trans rights. Catrgorizing differences as an act of violence now and in the past in a colonialist sense of differentiating humans from those who are inhummanized. Important to understand algorithmic bias in this context to understand it as an act of violence. The history of deception and detection (i.e who is seen as needing to decieve and how others attempt to ditect them). [Evil decievers and make believs on transphobic violence and the politics of illusion](https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1527-2001.2007.tb01090.x?casa_token=nctPQuAadoAAAAAA%3AtSN9oTsp-HvOMmr6tWEHxzww_3hlzLwzdmGcL-b7DwB-rxvZ6dVKkL1MXC654Gb8kp6lFefKX_7WvN-I). 

  ____
  ____
  ____
## Data collection Discussion Group

[Queer in AI](https://www.queerinai.org/)  @EurIPS 2025: Auditing Workshop

Hello! Thank you for joining a Queer in AI auditing workshop. Below is an interactive worksheet for completing with your group. Please submit one per group.

tailiamalloy@gmail.com  [Switch account](https://accounts.google.com/AccountChooser?continue=https://docs.google.com/forms/d/e/1FAIpQLSe0CfLds5wMQATpM2Ehn7Q3yU09KkQIgz1kt5uzcyc79m7__Q/viewform?urp%3Dgmail_link&service=wise)

Not shared

* Indicates required question

It is possible that Queer in AI will use the data from this session in a paper on queer auditing methods. If you are interested in being listed as an author on hypothetical paper... what are the names of your group members, and emails?

  

EX:  
Alissa Valentine, alissa.valentine@di.ku.dk

*

There are many ways of classifying digital harms, but one of the easiest to use is the 4Cs taxonomy (note: the Cs can overlap, so sometimes we add a 5th C for ‘Cross-Cutting’):

![](https://lh7-rt.googleusercontent.com/formsz/AN7BsVApUB7HOFbSsLA1_ORJLehcE5MOb9Cs-VNXEW5Dq7DZHNdWgR6v1gntOJ6mBUpcDUQ60lzwmSahpVw9zOAxCnjGVEuxbTIqNU7QYeTW-JZRFBJDGIgYMpJxNVXY_fyXJpitsUgQCeEAFiGmwSez-cXOS3_gLDHBO1R2MBT3DeM34MlzjnyX5bbzXJAy8rF4zyUl8-xVMqb3IcI4=w1704?key=bjevnUnMqE_K6okz3TNyFQ)

5 Stages in the AI lifecycle

![](https://lh7-rt.googleusercontent.com/formsz/AN7BsVBzk4yaQTR6SKLczGyvHYFMzcjq84c89KC0SfLNK-N8YfICria0eTcU-QDBxSwrnSWUHU445d5Ji2FZgga-eyp9xRLkilnfT9BJvK5nLT46rtY-PjeGMelUjFyBX5FQ3Q75kOvF072kj7ikOOvWf9fq1OWyH0O3JLA7Mo_ysXF530Lwcizx3ZTn8CxmWIfMsRKj77IOHEyauU3L=w1886?key=bjevnUnMqE_K6okz3TNyFQ)

Questions you want to ask for the lifecycle:

**1. Problem definition**: Who decided this problem needs solving? Whose needs were centered?

**2. Data collection and cleaning****:** Whose data is included? Whose is missing? Was consent meaningful?

**3. Model development****:** What assumptions are encoded? How are edge cases handled?

**4. System deployment****:** Who has access? Who is excluded? What recourse exists?

**6. Audit and evaluation****:** Who is evaluating? What metrics matter? Are affected communities involved?

What is your case study?  

Language: A mental health chatbot trained on therapist-patient transcripts is rolled out to reduce psychiatric wait times, including for queer youth.

Vision: A content moderation model automatically flags and removes images as "sexually explicit", but disproportionately targets queer creators and bodies.

Data privacy: A free AI chatbot monetizes by serving personalized ads based on what you disclose in conversation, including your identity, relationships, and struggles.

###  Data collection: Workers are hired to label toxic, hateful, and violent content so the model learns what to reject, exposing them to psychological harm for low pay.

What harms could occur? (Use the 4Cs)*

- Content 
1. Biases present in the people making these decisions could aplify the biases of content that is generted by AI systems. 
2. 
- Conduct 
3. People imbedding their inherent biases into the annotations... this is related to point 1 of content as one of the effects of this. 
- Contact 
4. Sustained harm caused by needing to do sonmething every day, it being a part of your job and identity can lead to accumulation of effects over long periods of time. 
- Contract 
5. These things typically happen in the global south because of the difference in value of labor in different areas.  
6. 
- Cross-Cutting

Where in the lifecycle could these harms be introduced?*
7. Mostly in the data collection part of the life cycle because it deals with how data is collected to train models. 
8. Also present in the problem definiiton. 

Where could interventions have prevented them?*
9. Diversity of annotations.  
10. Fair pay for annotators. 
11. A better understanding for the contracts that  the workers have. 
12. Psychological services for workers, healthcare, etc. 

What questions would you ask if you were auditing this system?*
13. How has exploitative collection of data from annotators been avoided. 
14. Is the quality of the data aligned with the values of the AI development cycle. 
15. What are the benefits and risks of changinf 
16. What are the assumptions built into the annotations.
17. What are the conflicts in what the annotators may want (doing their job, not getting fired, not being outed as being pro lgbtq in a unaccepting society. 
18. How can we ensure annotator diversity while protecting their individual privacy, safety, etc. 

Time to prepare for plenary! What are your 2-3 top findings? *

 [![Google](https://www.gstatic.com/images/branding/googlelogo/svg/googlelogo_dark_clr_74x24px.svg) Forms](https://www.google.com/forms/about/?utm_source=product&utm_medium=forms_logo&utm_campaign=forms)

____
____
____

### Category-Theoretic Wanderings into Interpretability

**Ian Rios-Sialer** | Independent Scholar

Category-Theoretic Wanderings into Interpretability is a piece of technical autotheory that asks how we can use category theory to frame interpretability. It queers the ecologies of knowledge, employing abstract mathematical language to discuss both intimate and technical frameworks. The work writes about love addiction, faithfulness in Anthropic's Circuit Tracing experiments, philosophical questions of meaning, and invites the field of AI Safety to feel their way through opacity.

Social media incitement of violenve, how does AI impact the risks associated with this. AI is more concerned with AGI taking over humanity instead of the real negative harms that have been done by AI systems and are continuing to happen.  So why does this happend in AI ethics? 
1. Some of it is from concerns that people have that are defined by beliefs like 'objective truth is superior to individual opinion' and 'cold rationality is superior to appeals to emmotion'. 
2. One way of understanding how this has happend is through category theory. 

Interpretability is an often targeted goal for AI, but even with deep understanding of how AI systems are designed, trained, and deployed, answering specific questions like 'why did chatGPT tell me not to text my situationship' are nearly impossible. Asking them directly doesn't work be cause models don't know factively why they generated the text that they did. Reasoning systems can gorund explanations in ways that make sense to people logically, i.e by supporting the position of the text that is generated, but this can still be incorrect. 


### Xenoreproduction: Exploration and Recovery of Collapsible Modes as Core AI Safety Objective

**Ian Rios-Sialer** | Independent Scholar

Generative AI models reproduce biases in data and amplify them through mode collapse. AI scholarship often overlooks perspectives from Queer Theory to understand such phenomena. This paper introduces Xenoreproduction as a core AI Safety objective, aimed at avoiding homogenization failure modes. Our formalism ties queerness and subalternity to collapsible modes.



### Que(e)rying Artificial Intelligence Use for Infectious Disease Surveillance

**Elise Racine** | University of Oxford & MATS

This presentation examines how AI for infectious disease surveillance could stigmatize and discriminate against vulnerable populations, particularly sexual and gender minorities (SGMs). Adopting an intersectional, reparative approach, the work proposes concrete steps towards a reparative algorithmic praxis: exploring how systems reproduce inequalities, centering sexual and gender diversity, and combating opacity through participatory governance mechanisms.

https://journals.sagepub.com/doi/pdf/10.1177/20539517241289440

In South Korea where queerness is highly stigmatized, an extensive surveillance system combined with unpreceded government sharing of personal information resulted in discrimination as queer individuals were identified, targeted, and blamed for rises in COVID-19 cases (Gitzen and Chun, 2021).
- Gitzen T and Chun W (2021) Pandemic surveillance and homophobia in South Korea. Insights from the Social Sciences, Social Science Research Council. Available at: https://items.ssrc.org/covid-19-and-the-social-sciences/covid-19-fieldnotes/pandemic-surveillance-and-homophobia-in-south-korea/

https://web.archive.org/web/20211201005457/https://www.queer-action-against-covid19.org/archives/category/english